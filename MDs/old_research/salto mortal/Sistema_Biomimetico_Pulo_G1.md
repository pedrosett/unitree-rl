# Sistema BiomimÃ©tico de Pulo - Unitree G1

## ğŸ¯ VisÃ£o Geral

**Data**: 12 de Agosto, 2025  
**Status**: EM TREINAMENTO (1000 iterations)  
**Arquitetura**: Aprendizado motor genuÃ­no sem forÃ§as externas

Este documento detalha a evoluÃ§Ã£o do sistema de pulo do Unitree G1 de uma implementaÃ§Ã£o com forÃ§as externas "mÃ¡gicas" para um **sistema biomimÃ©tico completo** que imita o movimento humano natural.

## ğŸš€ EvoluÃ§Ã£o do Sistema

### âŒ Problema Original: Sistema NÃ£o-FÃ­sico

**ImplementaÃ§Ã£o Anterior:**
```python
def apply_vertical_impulse(self, impulse):
    # AplicaÃ§Ã£o de forÃ§a externa "mÃ¡gica" de 1500N no torso
    forces[:, 0, 2] = impulse * 100.0  # ForÃ§a nÃ£o-fÃ­sica
```

**Problemas Identificados:**
- âŒ **NÃ£o transferÃ­vel**: RobÃ´s reais nÃ£o tÃªm "propulsores mÃ¡gicos"
- âŒ **ViolaÃ§Ã£o da fÃ­sica**: ForÃ§a aplicada externamente sem fonte
- âŒ **Reset constante**: ForÃ§a excessiva causava instabilidade (roll/pitch > limites)
- âŒ **NÃ£o biomÃ­mÃ©tico**: NÃ£o reproduz movimento humano natural

### âœ… SoluÃ§Ã£o Atual: Aprendizado Motor BiomimÃ©tico

**Nova Arquitetura:**
```python
def set_jump_command(self, jump_intent):
    """Sistema biomimÃ©tico completo de pulo com aterrissagem estÃ¡vel"""
    self.jump_command_buf[:, 0] = jump_intent  # Comando neural
    # RobÃ´ aprende sequÃªncia: agachar â†’ empurrar chÃ£o â†’ pular
```

## ğŸ§  Arquitetura Neural

### ObservaÃ§Ãµes Expandidas
```python
self.obs_buf = torch.cat((
    self.base_ang_vel * self.obs_scales.ang_vel,      # Estado dinÃ¢mico
    self.projected_gravity,                           # OrientaÃ§Ã£o
    self.commands[:, :3] * self.commands_scale,       # Comandos WASD
    (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos,  # PosiÃ§Ãµes juntas
    self.dof_vel * self.obs_scales.dof_vel,           # Velocidades juntas
    self.actions,                                     # AÃ§Ãµes anteriores
    sin_phase, cos_phase,                            # Fase da caminhada
    self.jump_command_buf  # ğŸ†• COMANDO DE PULO NEURAL
))
```

**DimensÃµes:**
- **ObservaÃ§Ãµes**: 48 (47 + 1 comando de pulo)
- **ObservaÃ§Ãµes Privilegiadas**: 51 (50 + 1 comando de pulo)
- **AÃ§Ãµes**: 12 (torques dos motores das juntas)

## ğŸƒâ€â™‚ï¸ Sistema de 5 Fases BiomimÃ©tico

### FASE 1: PreparaÃ§Ã£o (jump_preparation = 0.8)
```python
def _reward_jump_preparation(self):
    """Recompensa agachamento preparatÃ³rio quando jump_command=1.0"""
    # FlexÃ£o ideal: joelhos ~0.5 rad, quadris ~-0.3 rad
    knee_preparation = torch.exp(-torch.sum((knee_flex - 0.5)**2, dim=1))
    hip_preparation = torch.exp(-torch.sum((hip_flex + 0.3)**2, dim=1))
```

**Comportamento Esperado:**
- RobÃ´ recebe `jump_command=1.0` via SPACEBAR
- Aprende a flexionar joelhos e quadris (posiÃ§Ã£o de agachamento)
- Armazena energia potencial nas pernas

### FASE 2: Decolagem (jump_takeoff = 1.2)  
```python
def _reward_jump_takeoff(self):
    """Recompensa extensÃ£o coordenada das pernas durante decolagem"""
    # Detecta: pÃ©s no chÃ£o + velocidade vertical positiva
    taking_off = both_feet_contact & (vertical_velocity > 0.1)
    # Recompensa coordenaÃ§Ã£o entre pernas
    coordination = torch.exp(-torch.abs(leg_extension_vel[:, 0] - leg_extension_vel[:, 1]))
```

**FÃ­sica Natural:**
- ExtensÃ£o explosiva das pernas empurra contra o chÃ£o
- Lei de Newton: chÃ£o empurra robÃ´ para cima (reaÃ§Ã£o)
- **Sem forÃ§as externas** - apenas motores das juntas

### FASE 3: Voo (jump_airtime = 1.0)
```python
def _reward_jump_airtime(self):
    """Recompensa controle postural durante voo"""
    # Detecta fase aÃ©rea: sem contato com chÃ£o
    airborne = ~torch.any(feet_contact, dim=1)
    # Recompensa orientaÃ§Ã£o estÃ¡vel + altura
    orientation_stability = torch.exp(-torch.sum(self.base_ang_vel[:, :2]**2, dim=1))
```

**Controle AÃ©reo:**
- RobÃ´ aprende a manter orientaÃ§Ã£o estÃ¡vel no ar
- Sem contato com chÃ£o = sem controle direto
- Usa inÃ©rcia e pequenos ajustes para estabilidade

### FASE 4: Aterrissagem (jump_landing = 1.5) - **CRÃTICA**
```python
def _reward_jump_landing(self):
    """Recompensa aterrissagem controlada e estÃ¡vel"""
    # Detecta aterrissagem: velocidade vertical negativa + pÃ©s no chÃ£o
    landing = both_feet_contact & (vertical_velocity < -0.1)
    # AbsorÃ§Ã£o suave do impacto
    knee_absorption = torch.sum(torch.clamp(self.dof_pos[:, [3, 9]] - 0.2, 0, 0.4), dim=1)
```

**AbsorÃ§Ã£o de Impacto:**
- FlexÃ£o controlada das pernas absorve energia de queda
- Previne impactos bruscos que causariam reset
- MantÃ©m estabilidade pÃ³s-aterrissagem

### FASE 5: RecuperaÃ§Ã£o (jump_recovery = 0.7)
```python
def _reward_jump_recovery(self):
    """Recompensa recuperaÃ§Ã£o e continuaÃ§Ã£o do movimento"""
    # ManutenÃ§Ã£o do movimento horizontal original
    velocity_maintenance = torch.exp(-torch.abs(horizontal_vel - target_vel))
    upright_posture = torch.exp(-torch.sum(self.projected_gravity[:, :2]**2, dim=1))
```

**Continuidade de Movimento:**
- RobÃ´ retoma movimento WASD original apÃ³s pulo
- Fundamental para pulos durante caminhada/corrida
- IntegraÃ§Ã£o perfeita WASD + Pulo

## ğŸ® Interface de Controle

### Comando SPACEBAR
```python
# play.py - Nova implementaÃ§Ã£o
elif e.action == "cmd_jump":
    jump_cmd = JUMP_IMPULSE if pressed else 0.0  # 15.0 â†’ 1.0

# AplicaÃ§Ã£o do comando
def _apply_commands_to_env(_vx, _wz, _jump=0.0):
    env.commands[:, 0] = _vx   # Movimento X
    env.commands[:, 1] = 0.0   # Movimento Y  
    env.commands[:, 2] = _wz   # RotaÃ§Ã£o Z
    # ğŸ†• COMANDO NEURAL DE PULO
    if _jump > 0.0 and hasattr(env, 'set_jump_command'):
        env.set_jump_command(_jump)
```

### IntegraÃ§Ã£o WASD + Pulo
- **Durante movimento**: WASD + SPACEBAR = pulo dinÃ¢mico
- **Em repouso**: SPACEBAR = pulo vertical puro
- **Aterrissagem**: Continua movimento WASD original
- **Responsividade**: Sub-segundo de comando para execuÃ§Ã£o

## ğŸ“Š ConfiguraÃ§Ã£o de Treinamento

### ParÃ¢metros de Recompensa
```python
class scales(LeggedRobotCfg.rewards.scales):
    # Movimento base (mantido)
    tracking_lin_vel = 1.0      
    tracking_ang_vel = 1.2      
    alive = 0.15
    
    # ğŸ†• SISTEMA BIOMIMÃ‰TICO DE PULO - 5 FASES
    jump_preparation = 0.8      # Agachamento preparatÃ³rio
    jump_takeoff = 1.2         # ExtensÃ£o coordenada (MAIS IMPORTANTE)  
    jump_airtime = 1.0         # Controle postural em voo
    jump_landing = 1.5         # Aterrissagem controlada (CRÃTICO)
    jump_recovery = 0.7        # RecuperaÃ§Ã£o e continuaÃ§Ã£o
```

### ConfiguraÃ§Ã£o de Ambiente
```python
class env(LeggedRobotCfg.env):
    num_observations = 48      # +1 para jump_command_buf
    num_privileged_obs = 51    # +1 para jump_command_buf  
    num_actions = 12           # Torques motores (inalterado)
```

## ğŸš€ Treinamento Atual

### Comando de ExecuÃ§Ã£o
```bash
cd /home/pedro_setubal/Workspaces/unitree_rl/isaacgym/python/examples/unitree_rl_gym
python legged_gym/scripts/train.py --task g1 --max_iterations 1000 --headless
```

### Expectativas de Resultado

#### Performance Target
- **Episode Length**: >900 steps (estabilidade mantida)
- **Jumping Success Rate**: >80% (pulos bem-sucedidos)
- **Landing Stability**: >90% (aterrissagens sem reset)
- **Movement Integration**: Perfeita continuidade WASD+Pulo

#### Comportamentos Esperados
1. **Comando SPACEBAR** â†’ Agachamento preparatÃ³rio (0.2-0.5s)
2. **ExtensÃ£o explosiva** â†’ Decolagem natural das pernas
3. **Fase aÃ©rea** â†’ Controle postural estÃ¡vel (0.3-0.8s)
4. **Aterrissagem suave** â†’ AbsorÃ§Ã£o de impacto controlada
5. **RecuperaÃ§Ã£o** â†’ ContinuaÃ§Ã£o movimento WASD original

## ğŸŒŸ Vantagens do Sistema BiomimÃ©tico

### Transferibilidade Real
âœ… **100% TransferÃ­vel** - Usa apenas atuadores reais do robÃ´  
âœ… **Sem hardware adicional** - NÃ£o requer sensores/atuadores especiais  
âœ… **Robustez fÃ­sica** - Respeita limites reais de torque/velocidade

### Biomimetismo GenuÃ­no  
âœ… **SequÃªncia motora humana** - Agachar â†’ empurrar â†’ voar â†’ aterrissar  
âœ… **FÃ­sica natural** - ForÃ§a de reaÃ§Ã£o do chÃ£o (3Âª Lei de Newton)  
âœ… **Adaptabilidade** - Funciona em movimento, parado, diferentes velocidades

### IntegraÃ§Ã£o Perfeita
âœ… **WASD + Pulo simultÃ¢neo** - Pular durante caminhada/corrida  
âœ… **Continuidade de movimento** - MantÃ©m trajetÃ³ria pÃ³s-aterrissagem  
âœ… **Responsividade** - Comando instantÃ¢neo, execuÃ§Ã£o natural

## ğŸ“ˆ Monitoramento

### TensorBoard Metrics
- `rewards/jump_preparation` - Qualidade do agachamento
- `rewards/jump_takeoff` - CoordenaÃ§Ã£o da decolagem  
- `rewards/jump_airtime` - Controle aÃ©reo
- `rewards/jump_landing` - **MÃ‰TRICA CRÃTICA** - Estabilidade aterrissagem
- `rewards/jump_recovery` - ContinuaÃ§Ã£o do movimento

### Debug Console
```
ğŸ§  JUMP SEQUENCE INITIATED - Current velocity: [0.8, 0.0]
Episode reset at step 1000  # âœ… EpisÃ³dio completo sem reset
```

## ğŸ”® PrÃ³ximos Passos

1. **ConclusÃ£o do treinamento** (1000 iterations)
2. **ValidaÃ§Ã£o experimental** - Teste com diferentes velocidades WASD
3. **AnÃ¡lise de performance** - ComparaÃ§Ã£o com sistema anterior
4. **OtimizaÃ§Ã£o fine-tuning** - Ajuste de recompensas se necessÃ¡rio
5. **DocumentaÃ§Ã£o de resultados** - Benchmarks cientÃ­ficos finais

---

**ğŸ¤– Sistema desenvolvido com Claude Code - Focado em biomimetismo e transferibilidade real**

*Este sistema representa um avanÃ§o significativo no aprendizado de habilidades motoras complexas para robÃ´s humanoides, priorizando fÃ­sica natural e transferibilidade para aplicaÃ§Ãµes reais.*